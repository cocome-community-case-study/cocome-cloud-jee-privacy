\chapter{Privacy Analysis}
\label{ch:PrivacyAnalysis}

The Privacy Analysis represents the analysis stage in the MAPE-K feedback loop (\autoref{sec:Foundations:mape}). The goal is to check whether the runtime model contains any deployment related privacy violations. The privacy concept, described in \autoref{ch:PrivacyConcept}, states that privacy analysis consist of two major tasks. First, the correct privacy categorization for each software components needs to be determined. Second, the deployment evaluation, based on the deployment rules, defined in \autoref{sec:PrivacyConcept:deploymentrules}, needs to be performed.

The remaining chapter is divided into a theoretical part (\autoref{sec:PrivacyAnalysis:theory}), a component categorization part (\autoref{sec:PrivacyAnalysis:categorization}), a deployment evaluation part (\autoref{sec:PrivacyAnalysis:deployment}) and the implementation part (\autoref{sec:PrivacyAnalysis:implementation}).


\section{Analysis Theory}
\label{sec:PrivacyAnalysis:theory}

The exclusive source of information for the privacy analysis is the systems PCM Privacy runtime model. For an efficient analysis one first need to identify the minimal required information and substitute them, depending on the available sources.


\subsection{Required information}
In the context of Privacy Analysis there is a minimum of two pieces of information which are required for privacy analysis:

\begin{table}[h]
	\centering
	\begin{tabular}{r | l}
		\hline
		\textbf{\#} & \textbf{Required information for privacy analysis}\\
		\hline
		M1 & Information on components privacy level \\
		M2 & Information on components geo-location \\
		\hline
	\end{tabular}
	\caption{Minimal information for privacy analysis}
	\label{tab:pa_minimal_info}
\end{table}

Usually \textit{M1} and \textit{M2} is not directly available. As a consequence other ones must substitute these, while containing the same information. A suitable substitution, differs based on the sources and their contained information.

The used PCM Privacy meta-model provides a categorization of the communicated information between component interfaces. This enables a component classification, based on the most critical communication with another component. As a result, a components privacy level can be determined without knowing its exact purpose, analysing any inner processes or knowing the exact data-flow. So, $M1$ gets substituted by information about inter interface communication and its privacy categorization.

In order to get an information equivalent of $M2$, a components host must be determined, as well as that hosts geo-location. The PCM Privacy model provides these information. However, it is spread over multiple models. As a result we require only four pieces of information (\autoref{tab:iobserve_information}), compared to R-PRISs six pieces of information (\autoref{tab:rpris_information}).

\begin{table}[h]
	\centering
	\begin{tabular}{r | l}
		\hline
		\textbf{\#} & \textbf{Required information to carry out runtime check}\\
		\hline
		I1 & Interactions of two components per interface \\
		I2 & Information on component deployments on physical resources \\
		I3 & Geo-location information of physical resources \\
		I4 & Data Privacy categorization per interface communication \\
		\hline
	\end{tabular}
	\caption{iObserves information for runtime privacy checks}
	\label{tab:iobserve_information}
\end{table}

\subsection{Data-flow direction}
\label{sec:PrivacyAnalysis:theory:dataflow}
Usually component interfaces are categorized into providing and requiring interfaces. Interface connections are made between a pair of required and provided interfaces of the same type. This suggests a certain data- and control-flow direction. This is a wrong assumption. While there are cases, when the control-flow can be derived from this structure, the data-flow is completely independent from this categorization.

For example a database component (usually) only has provided interfaces. These interfaces allows the user to store and retrieve data from the database and therefore contains getter and setter methods. This means, there is no data-flow direction for the whole interfaces, since the data needs to "flow" into both directions. Note, that we are explicitly speaking of an interface as a whole, since individual methods can have a data-flow direction.

Information passed through an interface are available on the providing and requiring component. In other terms, if an component connector got categorized as \textit{Personal}, information of this type are available in both components. These components need to get categorized accordingly.

\subsection{Joining data streams}
\label{sec:PrivacyAnalysis:theory:jds}
In \autoref{sec:PrivacyConcept:deploymentrules} we elaborated on the danger of two \textit{Personally Identifiable Information} (Type 1) data streams, from two sources, joining on a single server. In such a case, the combination of these data streams could lead to personal, privacy relevant data. (Compare \autoref{enum:deployment_rules}, Rule 4). This concept applies on the described deployment level and also on the component categorization process.

While on deployment level, the information streams are not actively merged, this is a realistic possibility on the component categorization level. So the argument of applying an overestimation is not valid and this scenario must be taken seriously. In the following this special case will be refereed to as \textit{joining data streams} (short: JDS). In the following section, a couple of categorization and deployment examples will help clarifying this scenario.


\section{Component categorization}
\label{sec:PrivacyAnalysis:categorization}

The component categorization requires two tasks. The initial categorizing of every component and the analysis for with \textit{join data streams}.

The initial data privacy level of a component is equal the components most critical communication level (see \autoref{sec:PrivacyAnalysis:theory:dataflow}). This task is performed during the model graph construction. The search for joining data streams is more complex and requires a formalization, as well as an extended explanation. We will continue with the formal description, followed by an textual explanation and close with some examples.

\begin{description}
	\item{\textbf{Definitions}}
	\begin{itemize}
		\item The Graph $G := (N, E)$
		\item The Nodes $N$ consist of personal Nodes $p \in N_p$, depersonalised Nodes $d \in N_d$ and anonymized Nodes $a \in N_a$ $\wedge$ $N_p \cup N_d \cup N_a = N$ $\wedge$ $N_p \cap N_d \cap N_a = \{ \emptyset \} $
		\item The edges $E$ consist of personal Edges $e_p \in E_p$, depersonalised Edges $e_d \in E_d$ and anonymized Edges $e_a \in E_a$ $\wedge$ $E_p \cup E_d \cup E_a = E$ $\wedge$ $E_p \cap E_d \cap E_a = \{ \emptyset \} $ 
		\item Path $P = \langle(p_1, p_2, \dots, p_n), (e_1, e_2, \dots, e_{n-1})\rangle$ with $p \in N$ and $e \in E$
	\end{itemize}

	\item{\textbf{Formalization}}
\end{description}
\begin{gather*}
	\textrm{Every component is correctly categorized}\\
	\Leftrightarrow\\
	\nexists \textrm{ Path P } \textrm{ with let } {i, j} \in [0, n-1] \wedge i \neq j: e_i \neq e_j \wedge e_i \in E_d \\
	\wedge (p_2, p_3, \dots, p_{n-1}) \in N_d \wedge \{ p_1, p_n \} \in N_p \wedge n \geq 3
\end{gather*}

The formalization states, that every component in the graph $G$ is correctly categorized if no path from one personal component to a personal component exist. However, the path must traverse at least three components, while every edge is only used once and only depersonalised edges are used. Further, all internal nodes must have a depersonalised categorization.

When such a case is found, the depersonalised components of the path must be categorized as \textit{Personal}. As a result, the case is eliminated and categorization is corrected according to the \textit{joining data stream}. The following examples will illustrate the categorization and point out certain special cases.

\begin{figure}[h]
	\centering
	\includegraphics[trim = 35mm 40mm 40mm 45mm, clip, width=0.75\textwidth]{graphs/component_categorization_examples_initial}
	\caption{Initial component categorization}
	\label{fig:example_categorization:init}
\end{figure}

\autoref{fig:example_categorization:init} shows the components data privacy level after the initial categorization phase. \autoref{fig:example_categorization:base} shows the result of categorization analysis. The comparison of these two states show, that component D and E get "upcasted" and gain a \textit{Personal} - more critical - data privacy categorization. This is due to the fact, that component D and E have a connection onto two personal data sources (Component A and B). Applying the formalization, a path from component A to B via component E and D, using only depersonalised edges, can be found. This means, as mentioned above, a joining data stream exists and component D and E needs to be categorized as \textit{Personal}.

\begin{figure}[h]
	\centering
	\includegraphics[trim = 35mm 40mm 40mm 45mm, clip, width=0.75\textwidth]{graphs/component_categorization_examples_upcast_base}
	\caption{Post categorization analysis - basic example}
	\label{fig:example_categorization:base}
\end{figure}

Two special cases are shown in \autoref{fig:example_categorization:advanced}. So is component D categorized as \textit{Personal} even though it has only one other component as data source. However, it has two individual connections to component B, which could contain a joining data stream, since B has a personal categorization. The formalization states, that a personal component needs to be reached, while using every edge only once. This conditions are fulfilled.

\begin{figure}[H]
	\centering
	\includegraphics[trim = 35mm 40mm 40mm 45mm, clip, width=0.75\textwidth]{graphs/component_categorization_examples_upcast_advanced}
	\caption{Post categorization analysis - advanced example}
	\label{fig:example_categorization:advanced}
\end{figure}

Component F doesn't get an \textit{Personal} categorization since it can only contain privacy relevant data that are already present on component E. And component E has a depersonalized categorization. All anonymized categorized connections and components are ignored, since they don't contain any privacy related information. Applying the formalization, no path from A to a personal component can be found, using only depersonalised edges and each edge only once. So, the categorization is correct.


\section{Deployment analysis}
\label{sec:PrivacyAnalysis:deployment}

The deployment analysis' goal is to find out whether the current deployment is privacy compliant. A deployment is considered privacy compliant if no deployment violation is found. The rules for a privacy compliant deployment were described in \autoref{sec:PrivacyConcept:deploymentrules}. In the following we will formalize the deployment analysis, describe the formalization textually and finally give an example.

\begin{description}
	\item{\textbf{Definitions}}
	\begin{itemize}
		\item The Graph $G := (N, E, S)$ 
		\item The Nodes $N$ consist of personal Nodes $p \in N_p$, depersonalised Nodes $d \in N_d$ and anonymized Nodes $a \in N_a$ $\wedge$ $N_p \cup N_d \cup N_a = N$ $\wedge$ $N_p \cap N_d \cap N_a = \{ \emptyset \} $
		\item The edges $E$ consist of personal Edges $e_p \in E_p$, depersonalised Edges $e_d \in E_d$ and anonymized Edges $e_a \in E_a$ $\wedge$ $E_p \cup E_d \cup E_a = E$ $\wedge$ $E_p \cap E_d \cap E_a = \{ \emptyset \} $  
		\item The servers $S$ consist of save Servers $s_s \in S_s$ and un-save Servers $s_u \in S_u$ $\wedge$ $S_s \cup S_u = S$ $\wedge$ $S_u \cap S_s \cap N_a = \{ \emptyset \} $
		\item Let $N_{si}$ are the nodes deployed on server $s_i$
		\item Path $P = \langle(p_1, p_2, \dots, p_n), (e_1, e_2, \dots, e_{n-1})\rangle$ with $p \in N$ and $e \in E$
	\end{itemize}
	
	\item{\textbf{Formalization}}
\end{description}
\begin{gather*}
	\textrm{The deployment is illegal}\\
	\Leftrightarrow\\
	\exists n \in N_{si}: n \in N_p \wedge n \textrm{ deployed on } s_i \wedge s_i \in S_u \\
	\vee\\
	\exists s_x \in S_u \nexists \textrm{ Path  with } N_{sx} \subset P \wedge p_i \in N_d \wedge e_j \in E_d \\
	\vee \\
	\exists \textrm{ Paths } \{P_1, P_2, \dots, P_n\} \textrm{ from } N_p \textrm{ to } N_{si} \textrm{ with } i \in [0, n], j, k \in [0,|P_i|]: \\
	e_j \in E_d \wedge e_{pj} \cap e_{pk} = \{ \emptyset \} \wedge n \geq 2 
\end{gather*}

The formalization states three independent conditions for an illegal deployment. First, the deployment of an as personal categorized component on a server located in an un-save geo-location. Second, the depersonalised components on a un-save server are not connected. The potential connection must consist of depersonalised edges but can be transitive via depersonalised components and edges. The third condition states, that if there is more then one path, from the set of personal components to the depersonalised components hosted by an un-save server, then the deployment is illegal. However, must consist of individual, non overlapping and depersonalised edges.

\begin{figure}[h]
	\centering
	\includegraphics[trim = 35mm 30mm 30mm 25mm, clip, width=0.85\textwidth]{graphs/deployment_example_implementation_eval}
	\caption{Deployment analysis example}
	\label{fig:example_deplyoment_eval}
\end{figure}

\autoref{fig:example_deplyoment_eval} shows an illegal deployment. The deployment of Component A and B is obviously valid, due to its deployment on a "save" geo-location. Component C and F are also legally deployed, since both components share a single communication edge onto privacy relevant information and the "joining data streams" situation does not apply. Applying the formalization, the first condition is broken, since server \#3 does not host a personal component, the second condition is also false, since the components C and D are transitive and direct connected via depersonalised edges. The third condition does also not apply, since only one individual path via depersonalised edges from the personal components exists.

Server\#2, however, hosts an illegal deployment. Component D and E have different single data sources edges and can therefore save, process or transmit data, which can combine to privacy relevant data. The second and the third condition of the formal specification are true. So, are component E and D not transitively connected via depersonalised nodes. Further, two individual paths from the set of personal components to the components hosted by server \#2 exist.




\section{iObserve Privacy vs. R-PRIS}
\label{sec:PrivacyAnalysis:rpris}

R-PRIS from Schiemders et al. was introduced in \autoref{sec:RelatedWork:privacyanalysis}. In this section we are comparing the R-PRIS privacy analysis against the iObserve Privacy privacy analysis. More detailed information on R-PRIS can be found in \cite{Schmieders.}\cite{Schmieders.2015}.

\begin{description}
	\item[Runtime Model] R-PRIS uses the specially developed model shown in \autoref{fig:rpris_metamodel}. Even while it models components, VMs and process, it does not capture the systems architecture as the Palladio Component Model does. Further, it is not known, whether tool support or other compatible programs exist, like the PCM has. 
\end{description}

\begin{description}
	\item[Categorization] We are utilizing a component communication classification, which leads to a component classification and a deployment analysis. Therefore, we do not know what data are actually processed in a component or on a server. R-PRIS, however, tags the data itself, traces the transitive access and prohibits rule violating access. As a result, R-PRIS, uses the more accurate \textit{data tracking}, which requires more information then and a deep knowledge about the observed system then iObserve privacy. While iObserve privacy uses data categorization by hand, the R-PRIS approach does not explain their modelling and categorization process.
\end{description}

\begin{description}
	\item[Rule Compliance] iObserve Privacy is clearly build to stay EU General Data Protection Regulation and HIPAA compliant. Therefore, a simple file input with \textit{save} geo-locations is sufficient. R-PRIS requires a rule input, which specifies prohibited data access. Compared to iObserve privacy, this is a more powerful and flexible input. Nevertheless, it complicates the usage and scales poorly with the system size, deployment locations and data variety, since every prohibited access needs to be specified for every data type per geo-location and content type.
\end{description}



\section{Privacy Analysis implementation}
\label{sec:PrivacyAnalysis:implementation}

The PCM meta-model defines multiple models, each providing knowledge about a certain aspect of the target system (see \autoref{fig:pcm_info_spread}). This is not suited for an efficient privacy analysis and therefore requires an information preprocessing. So the implementation is spread over three steps:

\begin{enumerate}
	\label{enum:algorithm_steps}
	\setlength\itemsep{0em}
	\item build efficient data structure
	\item categorize components
	\item analyse deployment
\end{enumerate}


\subsection{Information preprocessing}
\label{sec:PrivacyAnalysis:implementation:prepro}

In the first algorithm phase, all informations $I1$ to $I4$ are extracted from the different models. $I1$ and $I4$ is part of the System models Assembly Connector Privacy. Where $I1$ consist of the Providing Assembly Context and the Requiring Assembly Context. $I4$ is the Data Privacy Level. $I3$ is a field in the Resource Container, which represents a server in the Resource Environment model. The Allocation model contains $I2$ in Allocation Contexts, which provide a mapping of an Assembly Contexts on a Resource Containers.

After extracting all required information, the basic data privacy level for every component/Assembly Context is calculated by applying the most critical privacy level from the corresponding Assembly Connectors.

As last step of the preprocessing, the data are reassembled by constructing a sufficient graph (\autoref{fig:privacy_graph_mm}). The graph is a simple, more direct representation of host-component-allocation structure from the PCM model. The graph contains two types of nodes: the DeploymentNode, a host representation, and the ComponentNode, a component representation. The data streams/interfaces are represented by the ComponentEdge:

\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\textwidth]{pictures/pcm_info_spread}
	\caption{PCM Privacy information spread}
	\label{fig:pcm_info_spread}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[trim = 00mm 120mm 15mm 50mm, clip, width=0.85\textwidth]{pictures/modelGraph_metamodel}
	\caption{Graphs meta-model for Privacy Analysis}
	\label{fig:privacy_graph_mm}
\end{figure}


\subsection{Component categorization implementation}

The second phase of the privacy analysis algorithm finalizes the component categorization. As described in \autoref{sec:PrivacyAnalysis:categorization}, joining data streams need to be found and fitting components' data privacy level corrected.

The algorithm (Algorithm \ref{algo:comp_categ}) searches for depersonalised-marked connections from one personal categorized component to another. It uses a \textit{deep search first} approach, while never using an edge twice. Note, that once a joining data stream is found, the involved components are appended to the list of personal components.

\begin{algorithm}[h]
	\caption{Component categorization algorithm}
	\label{algo:comp_categ}
\begin{algorithmic}[1]
	
	\State List of Components $components$
	\State Set of Edges $usedEdges$ 
	\State
	\Procedure{StartCategorization}{List<Components> $components$}\State
		$personalComponents\gets components with PrivacyLvl == PERSONAL$
		\ForAll{$personalComponent\gets Components$}\State
			\Call{clear}{ $usedEdges$ }\State
			\Call{TraverseComponent}{ $personalComponent$ }
		\EndFor
	\EndProcedure \State
	
	\Function{TraverseComponent}{Component $component$}\State
		$dePersonalEdges\gets component.$\Call{GetEdges}{} with $PrivacyLvl == DEPERSONAL$
		\ForAll{$edge\gets dePersonalEdges$}\State
			\If{$usedEdges.$\Call{Contains}{ $edge$ }} \State 
				\Call{Continue}{}
			\Else \State
				$usedEdges.$\Call{Add}{ $edge$ } \State
				$edgeParnter\gets edge.$\Call{GetEdgePartner}{ $component$ } \State
				
				\If {$edgeParnter.PrivacyLvl == PERSONAL$} \State
					\Return $edgeParnter$
				\Else \State
					$secondSource\gets$ \Call{TraverseComponent}{ $edgeParnter$ }
					\If{$secondSource \neq PERSONAL$} \State
						$component.PrivacyLvl\gets PERSONAL$ \State
						$components.$\Call{Add}{ $component$ } \State
						\Return $secondSource$
					\EndIf
				\EndIf 
			\EndIf
		\EndFor \State
		\Return Null
	\EndFunction
\end{algorithmic}
\end{algorithm}



\subsection{Deployment analysis implementation}

The final privacy analysis phase is the deployment evaluation. The base analysis is very simple, since it simply checks whether every as personal categorized component is deployed on an as save considered geo-location. The a geo-location is considered as save, when it is contained in the save-geo-location list. When a server is located in an un-save geo-location and contains more then one depersonalised component, an extensive analysis for joining data streams has to be made. This extensive analysis is described in Algorithm \autoref{algo:deployment_analysis}.

The Algorithm works similar to Algorithm \ref{algo:comp_categ}. Initially, it extracts all as depersonalised categorized components on the server. These components have to form a transitive hull and share a single depersonalised communication link to a single personal component. The algorithm uses a \textit{deep search first} approach to traverse through the components. If a second link to a personal component is found or not every depersonalised component on the server is reached, the deployment is illegal.

Note, that anonymized categorized components and edges can be ignored during analysis. Also, a server won't contain any personal marked component since such a deployment would be automatically illegal due to the servers un-save geo-location.


\begin{algorithm}[h]
	\caption{Deployment analysis algorithm}
	\label{algo:deployment_analysis}
	\begin{algorithmic}[1]
		
		\State Set of Components $compToReach$
		\State Set of Edges $usedEdges$
		\State Edge $dataSourceEdge$
		\State
		\Procedure{ExtensiveAnalysis}{Server $server$}
			\State $compToReach\gets server.$\Call{GetComponents}{} with $PrivacyLvl == DEPERSONAL$
			\State $dataSourceEdge \gets Null$
			\State $startComp\gets compToReach.$\Call{GetAny}{}
			\State {clear}{ $usedEdges$ }
			\State $singlePersonalDataSource\gets $\Call{TraverseComponent}{startComp}
			\State \Return $singlePersonalDataSource$ AND $compToReach.$\Call{IsEmpty}{} 
		\EndProcedure \State
		
		
		\Function{TraverseComponent}{Component $component$}
		\State $compToReach.$\Call{Remove}{ $component$ } 
		\State $dePersonalEdges\gets component.$\Call{GetEdges}{} with $PrivacyLvl == DEPERSONAL$\State
		
		\ForAll{$edge\gets dePersonalEdges$}
			\If{$usedEdges.$\Call{Contains}{ $edge$ }}
				\State \Call{Continue}{}
			\Else 
				\State $usedEdges.$\Call{Add}{ $edge$ } 
				\State $edgeParnter\gets edge.$\Call{GetEdgePartner}{ $component$ } 
				\State
				\If {$edgeParnter.PrivacyLvl == PERSONAL$}
					\If {$dataSourceEdge == Null$} 
					 	\State $dataSourceEdge \gets edge$
				 	\Else 
					 	\State \Return False
				 	\EndIf
				\Else \State
					$singleDataSource\gets$ \Call{TraverseComponent}{ $edgeParnter$ }
					\If{$singleDataSource$} 
						\State \Return False
					\EndIf
				\EndIf 
			\EndIf
		\EndFor 
		\State \Return True
		\EndFunction
	\end{algorithmic}
\end{algorithm}


